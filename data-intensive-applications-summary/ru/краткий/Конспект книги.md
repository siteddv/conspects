# Конспект книги "Проектирование высоконагруженных данными приложений"

Современные информационные системы сталкиваются с беспрецедентными вызовами: экспоненциальный рост объемов данных, необходимость обработки в реальном времени, требования к высокой доступности и масштабируемости. Проектирование таких систем требует глубокого понимания фундаментальных принципов работы с данными, распределенных вычислений и компромиссов между различными подходами.

## Основы проектирования информационных систем

Высоконагруженные данными приложения отличаются от традиционных программных систем тем, что их основная сложность связана не с вычислительными алгоритмами, а с объемом, сложностью и скоростью изменения данных. При создании таких систем необходимо балансировать три ключевых требования: надежность, масштабируемость и удобство сопровождения.

Надежность системы определяется ее способностью продолжать корректно выполнять функции даже при возникновении сбоев. Важно различать сбои (fault) — отклонение компонента от нормальной работы — и отказы (failure) — полную недоступность сервиса для пользователей. Критически важно разрабатывать механизмы, которые предотвращают переход сбоев в отказы. Источники проблем могут быть аппаратными (решаются через избыточность и резервирование), программными (требуют тщательного тестирования и мониторинга) или связанными с человеческим фактором (минимизируются интуитивными интерфейсами и автоматизацией).

Масштабируемость — это способность системы справляться с возросшей нагрузкой. Для правильного анализа необходимо точно описать параметры нагрузки: количество запросов в секунду, количество активных пользователей, соотношение операций чтения и записи. Производительность оценивается по пропускной способности для пакетной обработки и времени отклика для онлайн-систем. Время отклика представляет собой распределение значений, а не фиксированное число. Критически важны процентили, особенно верхние (p95, p99), так как они напрямую влияют на пользовательский опыт. Подходы к масштабированию делятся на вертикальное (использование более мощных машин) и горизонтальное (распределение нагрузки между множеством машин).

Удобство сопровождения определяет долгосрочную жизнеспособность системы. Основные затраты на разработку связаны не с первоначальным созданием, а с последующим сопровождением. Три принципа удобства сопровождения включают удобство эксплуатации (мониторинг, автоматизация, самовосстановление), простоту (снижение сложности через абстракции и четкие интерфейсы) и возможность развития (легкость внесения изменений и добавления новых функций).

## Модели данных и их эволюция

Выбор модели данных фундаментально влияет на процесс разработки и понимание решаемой проблемы. Приложения создаются путем наслоения моделей: объекты в памяти приложения преобразуются в JSON, XML или таблицы, которые затем кодируются в байты для хранения и передачи.

Реляционная модель, предложенная Эдгаром Коддом в 1970 году, организует данные в таблицы со строгими связями. С 1980-х годов реляционные системы управления базами данных (RDBMS) и язык SQL доминируют в индустрии. Однако в 2010-х годах возникло движение NoSQL, вызванное потребностью в горизонтальном масштабировании и специализированных операциях, которые плохо поддерживаются реляционными базами. Современная практика показывает, что полиглотное хранение — использование разных моделей данных для разных задач — становится нормой.

Объектно-реляционное несоответствие возникает из-за фундаментальных различий между объектной моделью программирования и реляционной моделью данных. ORM-фреймворки помогают смягчить эти различия, но не устраняют их полностью. Документоориентированные базы данных, такие как MongoDB, обеспечивают лучшую локальность данных — вся информация о сущности хранится в одном документе, что позволяет получить ее одним запросом вместо нескольких JOIN-операций. Однако документная модель плохо поддерживает связи "многие-ко-многим", которые естественно выражаются в реляционной модели.

Исторический контекст показывает эволюцию моделей данных: иерархическая модель IMS (1960-е), сетевая модель CODASYL (1970-е), реляционная модель (1980-е). Интересно, что документоориентированные базы данных сталкиваются с теми же проблемами, что и ранние иерархические системы. Современные системы демонстрируют сближение подходов: реляционные базы добавляют поддержку JSON, а документоориентированные базы внедряют возможности соединений.

Графоподобные модели данных подходят для сложных взаимосвязей "многие-ко-многим", где данные естественно представляются как вершины и ребра. Модели включают графы свойств (Neo4j, Titan) и хранилища тройных кортежей (Datomic, AllegroGraph). Специализированные языки запросов, такие как Cypher, SPARQL и Datalog, позволяют эффективно работать с графовыми структурами.

Языки запросов различаются по своей природе. SQL является декларативным языком — он описывает шаблон данных, которые нужно получить, а не алгоритм их извлечения. Оптимизатор СУБД самостоятельно выбирает индексы и методы соединения, что делает декларативные языки особенно подходящими для параллельного выполнения. MapReduce сочетает декларативные и императивные элементы, позволяя программистам явно контролировать процесс обработки.

## Внутреннее устройство систем хранения данных

Две ключевые задачи баз данных — сохранение данных и их эффективный поиск — определяют архитектуру систем хранения. Подсистемы делятся на две категории: OLTP (Online Transaction Processing) для обработки транзакций и OLAP (Online Analytical Processing) для аналитики.

Индексы ускоряют операции чтения, но замедляют записи, так как их необходимо обновлять при каждом изменении данных. Хеш-индексы используют хеш-карту в памяти, которая указывает на смещения в файле. Сегментация журнала и уплотнение решают проблему исчерпания места, но хеш-индексы ограничены необходимостью хранить всю карту в памяти и неэффективны для запросов по диапазону.

SS-таблицы (Sorted String Tables) и LSM-деревья (Log-Structured Merge Trees) хранят данные, упорядоченные по ключам. Это позволяет эффективно объединять сегменты и использовать разреженный индекс в памяти. MemTable в памяти записывается в SS-таблицу при превышении порога, а фоновое уплотнение объединяет сегменты. Этот подход используется в LevelDB, RocksDB, Cassandra и HBase. LSM-деревья обеспечивают высокую производительность записи благодаря меньшему усилению записи и лучшему сжатию по сравнению с B-деревьями.

B-деревья используют фиксированные страницы (обычно 4 КБ) и иерархию страниц для организации данных. Глубина дерева составляет O(log n), обычно 3-4 уровня для больших баз данных. WAL (Write-Ahead Log) обеспечивает надежность, а защелки управляют конкурентным доступом. Улучшения включают копирование при записи, сокращенные ключи и дополнительные указатели. B-деревья быстрее при чтении, но LSM-деревья превосходят их при записи.

Дополнительные типы индексов включают вторичные индексы для неуникальных ключей, кластеризованные индексы, где строки хранятся непосредственно в индексе, составные индексы для запросов по нескольким полям, многомерные индексы (R-деревья для геоданных) и полнотекстовый поиск (Lucene). In-memory базы данных, такие как Redis, VoltDB и Oracle TimesTen, исключают накладные расходы дисковых систем и обеспечивают чрезвычайно высокую производительность.

Различие между OLTP и OLAP фундаментально: OLTP-системы оптимизированы для поиска небольшого количества записей по ключу с низкой задержкой, в то время как OLAP-системы анализируют большие объемы данных, выполняя агрегирование и вычисление сводных статистик. Склады данных представляют собой отдельные базы данных с копиями данных из OLTP-систем. Процесс ETL (извлечение, преобразование, загрузка) переносит данные из операционных систем в аналитические. Схема "звезда" организует данные с таблицей фактов в центре, окруженной таблицами измерений.

Столбцовое хранилище революционизирует аналитическую обработку, храня данные по столбцам, а не по строкам. Это позволяет читать только необходимые столбцы, значительно ускоряя запросы. Сжатие данных особенно эффективно в столбцовом формате: битовые карты для повторяющихся значений позволяют эффективно выполнять запросы WHERE. Векторизованная обработка повышает эффективность использования CPU, обрабатывая целые столбцы за раз.

Порядок строк в столбцовом хранилище может быть оптимизирован под частые запросы, что улучшает сжатие. LSM-деревья решают проблему записи в столбцовые хранилища: данные сначала накапливаются в памяти, затем объединяются и записываются на диск. Материализованные представления сохраняют результаты запросов на диске, ускоряя агрегирование. OLAP-кубы организуют сводные показатели по измерениям, но менее гибки, чем запросы к исходным данным.

## Кодирование и эволюция данных

Совместимость данных критически важна для эволюции систем. Обратная совместимость означает, что новый код может читать старые данные, а прямая совместимость — что старый код может читать новые данные. Прямая совместимость сложнее, так как старый код должен игнорировать новые поля, которые он не понимает.

Кодирование (сериализация) преобразует данные из представления в памяти в последовательность байтов, а декодирование выполняет обратное преобразование. Языковые форматы, такие как Java Serializable и Python pickle, имеют серьезные недостатки: привязка к конкретному языку, проблемы безопасности, отсутствие контроля версий и неэффективность.

Текстовые форматы JSON, XML и CSV популярны благодаря человекочитаемости, но имеют проблемы с типами данных: числа могут терять точность, двоичные строки требуют кодирования Base64, что увеличивает объем на 33%. Двоичные форматы Thrift и Protocol Buffers используют схемы для определения структуры данных. Теги полей критически важны для эволюции: можно менять названия полей, но не теги. Новые поля добавляются с новыми тегами для обеспечения прямой совместимости, но не могут быть обязательными для обратной совместимости.

Avro использует схему без тегов, обеспечивая компактное кодирование (всего 32 байта на запись). Данные представляют собой последовательность значений без идентификации полей. Схема для записи и схема для чтения могут различаться, если они совместимы. Поля сопоставляются по именам, что обеспечивает гибкость для статически и динамически типизированных языков. Достоинства схем включают компактность, актуальную документацию, проверку совместимости и генерацию кода.

Данные движутся через системы различными способами. В базах данных записывающий процесс кодирует данные, а читающий декодирует их. Обратная совместимость критична, так как данные могут иметь разные временные метки, а время жизни данных часто превышает время жизни кода. Эволюция схемы позволяет базе данных выглядеть единообразно, несмотря на изменения в структуре.

REST представляет собой архитектурный стиль на основе HTTP, простой и понятный. SOAP — протокол на основе XML, более сложный и формализованный. Проблемы RPC включают непредсказуемость сетевых запросов, задержки, дублирование и проблемы совместимости типов. Современные фреймворки, такие как Thrift, gRPC и Avro, поддерживают RPC с различными форматами кодирования. Для эволюции RPC важна обратная совместимость запросов и прямая совместимость ответов.

Асинхронная передача сообщений через брокеры (RabbitMQ, Kafka) обеспечивает буферизацию, повторную отправку, скрытие деталей реализации и мультидоставляемость. Распределенные акторные фреймворки, такие как Akka, Orleans и Erlang OTP, используют асинхронные сообщения для масштабирования и отказоустойчивости.

## Репликация данных

Репликация — хранение копий данных на нескольких машинах — повышает доступность и производительность системы. Три основных алгоритма репликации: с одним ведущим узлом, с несколькими ведущими узлами и без ведущего узла.

Репликация с ведущим узлом использует одну реплику в качестве ведущей, которая принимает все записи, в то время как остальные ведомые реплики получают журнал изменений и применяют их. Чтение возможно с любых реплик, но запись выполняется только на ведущую. Синхронная репликация обеспечивает актуальность данных, но замедляет операции записи, так как ведущий узел ждет подтверждения от ведомых. Асинхронная репликация не требует ожидания, что ускоряет операции, но создает риск потери данных при сбое ведущего узла. Полусинхронная конфигурация использует один синхронный ведомый узел для баланса между производительностью и надежностью.

Создание новых ведомых узлов включает создание снимка состояния, копирование данных и подключение к журналу репликации. Отказ ведомого узла легко обрабатывается через восстановление из журнала изменений. Отказ ведущего узла требует более сложной процедуры failover: установление факта отказа, выбор нового ведущего узла и перенастройка клиентов. Проблемы включают возможную потерю данных при асинхронной репликации и риск разделения вычислительных мощностей.

Методы репликации различаются по уровню абстракции. Операторная репликация передает SQL-команды, но имеет проблемы с недетерминированными функциями. Перенос WAL (Write-Ahead Log) работает на низком уровне, но создает проблемы совместимости версий. Логическая построчная репликация отделяет процесс от структуры хранения, обеспечивая совместимость версий и поддерживая CDC (Change Data Capture). Триггерная репликация обеспечивает максимальную гибкость, но имеет более высокие накладные расходы.

Асинхронная репликация приводит к конечной согласованности: данные на ведомых узлах могут быть устаревшими. Проблема "чтение после записи" возникает, когда пользователь должен видеть свои собственные изменения. Решения включают чтение с ведущего узла для недавно измененных данных, отслеживание времени обновления, использование меток времени и маршрутизацию в один центр обработки данных. Монотонное чтение предотвращает "движение во времени назад" через чтение с одной реплики для каждого пользователя. Согласованное префиксное чтение сохраняет причинно-следственную связь, записывая связанные операции в одну секцию.

Репликация с несколькими ведущими узлами позволяет нескольким узлам обрабатывать записи и обмениваться изменениями. Сценарии использования включают несколько центров обработки данных для независимости при сбоях и локальной обработки, офлайн-клиенты, где каждое устройство является ведущим узлом, и совместное редактирование документов. Обработка конфликтов становится критической: асинхронное обнаружение означает, что конфликты обнаруживаются позже. Предотвращение конфликтов возможно через маршрутизацию всех изменений записи через один узел. Конвергентное разрешение включает LWW (Last Write Wins, что может привести к потере данных), объединение значений, сохранение конфликтов для пользователя и использование CRDT (Conflict-free Replicated Data Types) или операционального преобразования.

Репликация без ведущего узла позволяет клиентам отправлять записи на несколько реплик. Кворумная система гарантирует, что w + r > n, где w — количество подтверждений записи, r — количество реплик для чтения, а n — общее количество реплик. Это гарантирует пересечение множеств записи и чтения. Настройка w и r позволяет балансировать между производительностью и согласованностью. Нестрогий кворум выполняет операции на доступных узлах с направленной передачей при восстановлении, повышая доступность, но не гарантируя актуальность.

Обнаружение конкурентных операций использует отношение "происходит до" для определения конкурентности. Номера версий позволяют различать перезапись и конкурентные записи. Векторы версий отслеживают версии каждой реплики для корректного слияния. Слияние конкурентных значений может использовать CRDT, отметки об удалении (tombstones) и другие алгоритмы.

## Секционирование для масштабирования

Секционирование (sharding) необходимо для масштабируемости при больших объемах данных. Разбиение данных на секции, хранящиеся на разных узлах, улучшает производительность и пропускную способность. Секционирование и репликация дополняют друг друга: каждая секция реплицируется для отказоустойчивости.

Секционирование данных типа "ключ — значение" может выполняться по диапазонам, где ключи сортируются, и каждая секция содержит определенный диапазон. Преимущества включают эффективные запросы по диапазонам, но возможны горячие точки при частых обращениях к соседним ключам. Хеш-секционирование использует хеш ключа для определения секции, обеспечивая равномерное распределение нагрузки, но делая неэффективными запросы по диапазонам. Гибридные подходы используют составные ключи с хешированием и сортировкой для баланса.

Вторичные индексы создают дополнительные сложности при секционировании. Локальные индексы хранятся в секции с данными, что упрощает записи, но усложняет чтение, так как запросы могут требовать обращения к нескольким секциям. Глобальные индексы секционируются отдельно, что упрощает чтение, но усложняет записи, так как обновление записи требует обновления нескольких секций индекса.

Перебалансировка секций необходима при изменении количества узлов или распределения данных. Хеширование по модулю N неэффективно, так как требует перемещения большинства данных. Фиксированное количество секций, большее, чем количество узлов, позволяет перераспределять секции между узлами. Динамическое секционирование автоматически разбивает и объединяет секции при необходимости. Секционирование пропорционально количеству узлов обеспечивает равномерное распределение. Цель перебалансировки — равномерное распределение нагрузки, минимизация перемещений данных и минимальные перебои в работе.

Маршрутизация запросов может выполняться через балансировщик нагрузки, маршрутизирующее звено или прямое подключение клиентов. Сервисы координации, такие как ZooKeeper, отслеживают распределение секций. Gossip-протокол, используемый в Cassandra и Riak, позволяет узлам обмениваться информацией без центрального сервиса. MPP-системы (Massively Parallel Processing) выполняют запросы параллельно на множестве узлов.

## Транзакции и изоляция

Транзакции группируют операции в логическую единицу: все операции выполняются успешно или все откатываются. Это упрощает обработку ошибок, но требует затрат на производительность. ACID определяет свойства транзакций: атомарность (все или ничего), согласованность (инварианты сохраняются), изоляция (конкурентный доступ не создает проблем) и сохраняемость (данные записываются на диск). Не все базы данных строго следуют всем принципам ACID.

Слабые уровни изоляции защищают от некоторых, но не от всех аномалий. Грязные чтения возникают при чтении незафиксированных данных, решаются чтением только зафиксированных данных. Грязные записи предотвращаются блокировками. Невоспроизводимое чтение возникает, когда данные изменяются между чтениями в одной транзакции, решается изоляцией снимков состояния (MVCC — Multi-Version Concurrency Control). Потерянные обновления происходят при цикле чтение-изменение-запись, где изменения перезаписываются, решаются блокировками (SELECT FOR UPDATE) или автоматическим обнаружением. Фантомные чтения возникают при изменении набора данных между чтениями, решаются блокировками по диапазону или индексами предикатов.

Сериализуемость — самый сильный уровень изоляции, предотвращающий все аномалии. Три основных подхода включают последовательное выполнение, где одна транзакция выполняется за раз, эффективно при высокой скорости, но ограничено одним ядром. Двухфазная блокировка (2PL) использует блокировки для чтения и записи со строгими правилами, это стандартный подход, но имеет плохую производительность из-за блокировок. Сериализуемая изоляция снимков состояния (SSI) использует оптимистический подход, проверяя сериализуемость перед фиксацией, что улучшает производительность и устраняет недостатки 2PL.

## Проблемы распределенных систем

Распределенные системы принципиально отличаются от однопроцессных наличием частичных отказов. Нет глобального источника истины, время и синхронизация ненадежны. Частичные отказы — определяющая характеристика распределенных систем: при действиях с другими узлами возможны сбой, замедление или полное прекращение ответа. Система должна быть устойчива к частичным отказам.

Ненадежные сети создают вероятность потери или задержки пакетов. Невозможно узнать, дошло ли сообщение при отсутствии ответа. Неоднородность задержек может привести к ошибочному предположению о сбое узла. Узел может работать хуже, чем обычно, со снижением пропускной способности, что сложнее обнаружить, чем явный отказ.

Ненадежные часы представляют серьезную проблему: часы узла могут быть рассинхронизированы, несмотря на использование NTP (Network Time Protocol). Часы могут перескакивать вперед или назад. Полагаться на часы опасно, так как неизвестен интервал погрешности. Использование часов для упорядочивания событий может привести к потере данных или неправильному порядку операций.

Обнаружение сбоев не имеет безошибочных механизмов. Большинство алгоритмов определяет доступность по времени ожидания ответа. Невозможно различать сетевые отказы и отказы узлов. Обработка сбоев усложняется отсутствием глобальных переменных, разделяемой памяти и общих знаний. Узлы не могут согласовать время. Единственный способ передачи информации — ненадежная сеть. Необходимы протоколы с кворумом для согласования решений между узлами. Ограждающие маркеры защищают от устаревших операций и обрабатывают конфликты при конкурентных записях.

## Согласованность и консенсус

Модели согласованности варьируются от конечной согласованности до линеаризуемости. Конечная согласованность — слабая модель, где данные со временем сходятся к согласованному состоянию. Ограничения включают устаревшие данные и проблемы для разработчиков, которые должны учитывать возможные несоответствия. Согласованность чтения после записи гарантирует, что пользователь видит свои собственные изменения. Монотонное чтение предотвращает "движение во времени назад". Согласованное префиксное чтение сохраняет причинно-следственную связь между операциями.

Линеаризуемость обеспечивает, что реплицированные данные выглядят как одна копия, и все операции атомарны. Это легко понять, но замедляет систему, особенно при больших сетевых задержках. Теорема CAP утверждает, что нельзя одновременно обеспечить согласованность, доступность и устойчивость к разделению сети. Реализация линеаризуемости требует синхронной репликации с ведущим узлом или консенсусных алгоритмов, что создает ограничения по производительности и задержкам.

Причинность представляет более слабую модель, чем линеаризуемость, но более эффективную. Она соблюдает последовательность событий на основе причинно-следственных связей. Отдельные события могут быть конкурентными, если между ними нет причинно-следственной связи. Временные метки Лампорта отслеживают причинно-следственный порядок, но недостаточны для некоторых задач, таких как обеспечение уникальности имени пользователя. Рассылка общей последовательности — протокол обмена сообщениями с надежной доставкой и полностью упорядоченной доставкой — эквивалентна консенсусу.

Распределенные транзакции и консенсус представляют фундаментальные проблемы распределенных систем. Двухфазная фиксация (2PC) использует координатора и участников, но является блокирующим протоколом: при сбое координатора участники могут застрять, удерживая блокировки долгое время. Отказоустойчивые консенсусные алгоритмы, такие как Paxos, Raft (используется в etcd) и Zab (используется в ZooKeeper), реализуют рассылку общей последовательности. Они используют ведущий узел с гарантией уникальности в период, но имеют ограничения: требуют синхронной репликации, строгого большинства, фиксированного набора узлов и чувствительны к сетевым проблемам.

Сервисы координации, такие как ZooKeeper и etcd, предоставляют практические реализации консенсуса с дополнительными функциями: линеаризуемые атомарные операции, общая последовательность операций, обнаружение сбоев и уведомления об изменениях. Многие проблемы распределенных систем эквивалентны консенсусу: линейные реестры, атомарная транзакция, рассылка общей последовательности, блокировки, сервис членства и ограничение уникальности.

## Пакетная обработка данных

Пакетная обработка обрабатывает большие объемы данных на множестве машин. Философия Unix, основанная на небольших инструментах с неизменяемыми входными данными, переносится в MapReduce и современные системы обработки данных. Принципы включают неизменяемость входных данных, использование выходных данных как входных для других программ и создание небольших инструментов, которые "хорошо делают что-то одно". Стандартный интерфейс обеспечивается через файлы и каналы.

MapReduce представляет модель программирования с функциями map и reduce, распределенную на тысячи компьютеров. Входные и выходные данные хранятся в распределенной файловой системе, такой как HDFS (Hadoop Distributed File System). Секционирование размещает функции map по входным блокам. Выходные данные переупорядочиваются, сортируются и объединяются в разделы сжатия, чтобы связанные данные с одинаковым ключом находились в одной секции. Отказоустойчивость обеспечивается записью на диск, что упрощает восстановление, но замедляет выполнение. Детерминированные операторы сокращают объем пересчета при сбоях.

Алгоритмы объединения включают сортировку слияния для больших наборов данных, широковещательное объединение по хешу для малых наборов, которые помещаются в память, и секционированные хеш-объединения, где оба набора данных секционированы одинаковым образом.

Современные альтернативы MapReduce, такие как Spark, Tez и Flink, рассматривают весь рабочий процесс как одну задачу, без разделения на независимые подзадачи. Они избегают материализации промежуточных состояний на диск, держа больше данных в памяти, что значительно ускоряет обработку. Модель программирования основана на чистых функциях без побочных эффектов, что позволяет системе скрыть проблемы распределенных систем: безопасное повторение задач и отбрасывание выходных данных неудачных задач.

## Потоковая обработка данных

Потоковая обработка выполняется непрерывно для неограниченных потоков событий, в отличие от пакетной обработки фиксированных наборов данных. Два типа брокеров сообщений различаются по своей модели: AMQP/JMS отправляют сообщения потребителям, подтверждения удаляют сообщения, что подходит для асинхронной формы RPC и очередей задач. Брокеры на основе журналирования, такие как Kafka, обеспечивают, что все сообщения из раздела доставляются одному потребителю в одном порядке. Параллелизм достигается через секционирование, а отслеживание прогресса — через смещения. Сохранение на диске позволяет перечитывать старые сообщения.

Представление баз данных в виде потоков открывает новые возможности для интеграции. Фиксация истории изменений через CDC (Change Data Capture) или источники событий создает поток всех изменений в базе данных. Уплотнение журнала позволяет потоку сохранять полную копию содержимого базы данных, что делает возможным создание производных информационных систем. Поддержание актуальности индексов, кэшей и аналитических систем через потребление журнала изменений позволяет создавать новые представления для существующих данных без изменения исходных систем.

Обработка потоков применяется для поиска событий по шаблону, вычисления оконных агрегаций и поддержания производных систем в актуальном состоянии. Трудности с временем возникают из-за различий между временем обработки и временными метками событий, а также проблемы событий, появляющихся после закрытия временного окна.

Три типа объединений потоков решают различные задачи. Поток-поток объединение работает с двумя потоками событий активности, ища связанные события в интервале времени. Поток-таблица объединение использует один поток событий и обновления таблицы, где потоковый процессор подписывается на журнал изменений. Таблица-таблица объединение работает с двумя потоками обновлений таблиц, например, для создания ленты Twitter. Отказоустойчивость требует средств поддержания состояния и повторения сообщений для объединения потоков и обеспечения надежности.

## Будущее информационных систем

Интеграция данных становится критической задачей, так как нет одного инструмента для всех вариантов использования. Необходимо комбинировать разные продукты, решая проблему интеграции через пакетную обработку и потоки событий. Метод разделения систем различает системы записи и системы, получающие данные через преобразования. Поддержание индексов, материализованных представлений, моделей машинного обучения и статистических сводок создает производные системы. Асинхронные и слабосвязанные преобразования повышают надежность и масштабируемость.

Развитие приложений рассматривает потоки данных как преобразования. Изменение этапа обработки означает запуск нового кода для всего набора входных данных. Исправление ошибок требует повторной обработки данных, что становится возможным благодаря неизменяемости и журналированию.

Отделение от баз данных означает разделение компонентов базы данных и построение приложения из слабосвязанных компонентов. Процессы похожи на реализованные внутри базы данных, но выполняются как отдельные сервисы. Производное состояние обновляется через отслеживание изменений в базовых данных. Поток данных до конечного пользователя обеспечивает динамически обновляемые пользовательские интерфейсы и работу в автономном режиме.

Стремление к корректности требует обеспечения правильной обработки при сбоях. Надежные гарантии целостности достигаются через асинхронную обработку событий, сквозные идентификаторы операций для идемпотентности и асинхронную проверку ограничений. Клиенты могут ждать проверки или продолжить работу с последующими извинениями при нарушении ограничений. Этот подход более масштабируем и надежен, чем распределенные транзакции.

Системы без координации структурируются вокруг потока данных с асинхронной проверкой ограничений. Избежание избыточной координации сохраняет целостность при географическом распределении и сбоях. Аудит позволяет проверять целостность и обнаруживать повреждения данных.

Этические аспекты построения высоконагруженных данными приложений становятся все более важными. Данные могут причинить ущерб через решения, влияющие на жизнь людей, дискриминацию, слежку и раскрытие конфиденциальной информации. Непредвиденные последствия использования данных требуют тщательного рассмотрения. Разработчики несут ответственность за создание программного обеспечения и систем, которые направлены в мир, в котором они хотят жить — гуманный и уважительный к людям. Ответственность разработчиков распространяется не только на техническую корректность, но и на этические последствия их работы.

## Заключение

Проектирование высоконагруженных данными приложений требует глубокого понимания компромиссов между различными подходами. Выбор модели данных зависит от типов связей и паттернов доступа. Системы хранения оптимизируются для различных рабочих нагрузок: OLTP для транзакций, OLAP для аналитики. Распределение данных через репликацию и секционирование обеспечивает масштабируемость и отказоустойчивость, но создает сложности с согласованностью.

Транзакции упрощают программирование, но требуют компромиссов в производительности. Распределенные системы принципиально отличаются от централизованных наличием частичных отказов и ненадежностью сетей и часов. Согласованность варьируется от конечной до линеаризуемости, каждая модель имеет свои компромиссы. Консенсус представляет фундаментальную проблему, к которой сводятся многие другие.

Пакетная и потоковая обработка обеспечивают интеграцию данных и создание производных систем. Асинхронные преобразования повышают надежность и масштабируемость. Отделение от баз данных позволяет строить гибкие, слабосвязанные системы. Стремление к корректности требует новых подходов, выходящих за рамки традиционных транзакций.

Этические аспекты становятся неотъемлемой частью проектирования систем. Разработчики должны учитывать последствия использования данных и нести ответственность за создание систем, которые приносят пользу, а не вред. Техническое мастерство должно сочетаться с этическим мышлением для создания действительно ценных информационных систем.
