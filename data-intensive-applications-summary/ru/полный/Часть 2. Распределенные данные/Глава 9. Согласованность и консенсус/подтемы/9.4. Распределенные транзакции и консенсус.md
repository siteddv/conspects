Консенсус является одной из важнейших и фундаментальных проблем распределенных вычислений. На первый взгляд все кажется легким: говоря простыми словами, цель состоит в том, чтобы заставить несколько узлов согласовать некие объекты. Однако многие системы были разрушены, поскольку их создатели исходили из ошибочного убеждения, что данную проблему легко решить.

## Ситуации, требующие консенсуса

Существует ряд ситуаций, в которых важно, чтобы узлы были согласованными:

- **Выбор ведущего узла**: в базе данных с репликацией с одним ведущим узлом все узлы должны прийти к единому мнению о том, какой из них является ведущим
- **Атомарная фиксация**: в базе данных, которая поддерживает транзакции, охватывающие несколько узлов или разделов, нужно заставить все узлы согласовать исход транзакции: либо во всех узлах она будет прервана/произойдет откат, либо же во всех узлах будет подтверждена

## Невозможность консенсуса

Результаты FLP (Фишер, Линч, Патерсон) доказывают невозможность построить алгоритм, который бы всегда позволял достичь консенсуса, если в узле возможен сбой. Однако этот результат подтвержден в модели асинхронной системы — очень ограниченной модели, предполагающей детерминированный алгоритм, который не может использовать часы или задержки.

Когда в алгоритме разрешено применять задержки или какой-либо другой способ идентификации узлов, в которых, вероятно, произошел сбой (даже если иногда такое подозрение ошибочно), консенсус становится достижимым. Даже простого позволения алгоритму задействовать случайные числа уже достаточно, чтобы обойти выводы о его невозможности.

Таким образом, несмотря на то что результат FLP о невозможности консенсуса имеет большое теоретическое значение, на практике в распределенных системах консенсус обычно достижим.

## Атомарная и двухфазная фиксация (2PC)

**Двухфазная фиксация** (2PC) является алгоритмом для атомарной фиксации транзакций в случае нескольких узлов. Она гарантирует, что все узлы либо зафиксировали транзакцию, либо прервали ее.

### Основная схема 2PC

В 2PC используется новый компонент — **координатор** (также известный как диспетчер транзакций). Процесс фиксации/прерывания в 2PC разбит на две фазы:

**Этап 1 — Подготовка:**
- Координатор отправляет запрос на подготовку каждому из узлов, спрашивая их, могут ли они выполнить фиксацию
- Участники должны убедиться, что точно могут завершить транзакцию при любых обстоятельствах, в том числе записать все данные транзакции на диск
- Отвечая координатору «да», узел обещает завершить транзакцию без ошибок в случае надобности. Участник отказывается от права отменить транзакцию, но фактически не совершает ее

**Этап 2 — Фиксация или прерывание:**
- Если все участники ответили «да», то координатор отправляет запрос фиксации и выполняется фиксация
- Если один из участников ответил «нет», то координатор отправляет всем узлам запрос прерывания

### Система обещаний

В протоколе 2PC есть две критические точки невозврата:
1. Когда участник отвечает «да», он обещает, что гарантированно сможет позднее завершить транзакцию (хотя координатор все еще может отказаться от нее)
2. Как только координатор принимает решение, оно является бесповоротным

Эти гарантии обеспечивают атомарность 2PC. Координатор записывает свое решение на диск в свой журнал транзакций, чтобы впоследствии, в случае сбоя, знать, какое решение было принято. Это называется **точкой фиксации**.

### Отказ координатора

Если с координатором случится сбой перед отправкой запросов на подготовку, то участник может безопасно отменить транзакцию. Но, как только участник получил запрос на подготовку и ответил «да», он больше не может отменить транзакцию в одностороннем порядке — ему следует дождаться ответа от координатора. Транзакция участника в таком состоянии называется **сомнительной** или **неопределенной**.

Единственный способ, которым может завершиться процедура 2PC, — это ожидание восстановления координатора. Координатор должен записать свое решение о фиксации или отмене транзакции в журнал транзакций на диске, прежде чем отправлять участникам запросы о фиксации или отмене транзакции.

### Блокировка во время неопределенности

Проблема заключается в блокировке. Транзакции базы данных обычно используют эксклюзивную блокировку на уровне строк для любых строк, которые они изменяют. База данных не может снять эти блокировки до тех пор, пока транзакция не будет завершена или прервана.

При использовании двухфазной фиксации транзакция должна сохранять блокировки все время, пока находится в состоянии неопределенности. При выходе координатора из строя и повторном включении через 20 минут эти блокировки будут удерживаться в течение 20 минут. Если по какой-то причине журнал координатора будет полностью потерян, то блокировки будут сохраняться вечно или по крайней мере до тех пор, пока администратор не решит проблему вручную.

### Трехфазная фиксация

Двухфазную фиксацию называют **блокирующим протоколом** атомарной фиксации из-за того, что 2PC способна зависнуть в ожидании восстановления координатора.

В качестве альтернативы 2PC был предложен алгоритм, называемый **трехфазной фиксацией** (3PC). Однако он предполагает наличие сети с ограниченной задержкой и узлами с ограниченным временем отклика; в большинстве реальных систем с неограниченными сетевыми задержками и паузами процессов он не гарантирует атомарность.

## Распределенные транзакции на практике

Распределенные транзакции, особенно реализованные с двухфазной фиксацией, имеют смешанную репутацию. С одной стороны, они предоставляют гарантию безопасности, которой было бы трудно добиться иными средствами. С другой — их критикуют за то, что они вызывают операционные проблемы, практически убивают производительность и обещают больше, чем могут выполнить.

### Два типа распределенных транзакций

- **Внутренние распределенные транзакции базы данных**: некоторые распределенные БД поддерживают внутренние транзакции между узлами самой базы. В этом случае все узлы, участвующие в транзакции, задействуют одно и то же программное обеспечение БД.
- **Гетерогенные распределенные транзакции**: участниками гетерогенной транзакции являются разные технологии: например, две БД разных производителей или даже системы без БД, такие как брокеры сообщений.

Внутренние транзакции базы данных не должны быть совместимы с какой-либо другой системой, так что в них может использоваться любой протокол и применяться оптимизация, специфичная для этой конкретной технологии. Гетерогенные транзакции гораздо сложнее.

### XA-транзакции

**X/Open XA** (eXtended Architecture) — это стандарт для реализации двухфазной фиксации в гетерогенных технологиях. XA поддерживается во многих традиционных реляционных базах данных и брокерах сообщений.

XA не является сетевым протоколом — это просто C API для взаимодействия с координатором транзакций. Координатор транзакций реализует XA API и часто представляет собой обычную библиотеку, загружаемую в тот же процесс, что и приложение.

### Ограничения для распределенных транзакций

- Если координатор не реплицируется, а работает только на одной машине, то это является возможной точкой отказа всей системы
- Многие серверные приложения разрабатываются по модели без учета состояния, но координатор меняет характер развертывания — журналы координатора становятся важной частью долговременного состояния системы
- Поскольку XA-транзакции должны быть совместимы с широким спектром систем данных, они обязательно являются наименьшим общим знаменателем
- Для успешного завершения транзакции 2PC все участники должны дать ответы. Следовательно, если любая часть системы нарушена, то транзакция тоже не состоится

## Отказоустойчивый консенсус

Если отойти от строгих определений, то консенсус означает достижение согласованности между несколькими узлами по какому-то вопросу.

### Формальное определение консенсуса

Консенсусный алгоритм должен удовлетворять следующим требованиям:

- **Единое решение**: никакие два узла не могут получить разные решения
- **Целостность**: ни один узел не получает два решения
- **Действительность**: если узел выбирает решение v, то v было предложено другим узлом
- **Завершенность**: каждый узел, который не вышел из строя, в конечном итоге выбирает то или иное значение

Единое решение и целостность определяют основную идею консенсуса: каждый раз выбирается один результат и, как только это произошло, решение не может быть изменено.

### Системная модель консенсуса

Системная модель консенсуса предполагает, что, когда узел выходит из строя, он внезапно исчезает из сети и больше не возвращается. В этой системной модели любой алгоритм, который предлагает ожидать восстановления узла, не сможет удовлетворить требованию завершенности. В частности, 2PC не соответствует данному требованию.

**Ограничение по количеству отказов:** можно доказать, что любой консенсусный алгоритм требует правильного функционирования по крайней мере большинства узлов с целью гарантировать завершенность. Это большинство может безопасно сформировать кворум.

Таким образом, свойство завершенности основано на предположении, что менее половины узлов вышли из строя или недоступны. Однако большинство реализаций консенсуса гарантируют, что свойства безопасности выполняются всегда, даже если большинство узлов вышли из строя.

## Консенсусные алгоритмы и рассылка общей последовательности

Наиболее известными отказоустойчивыми консенсусными алгоритмами являются Viewstamped Replication (VSR), Paxos, Raft и Zab.

Большинство упомянутых алгоритмов фактически не используют непосредственно формальную модель консенсуса. Вместо этого они принимают решение о последовательности значений, что делает их алгоритмами рассылки общей последовательности.

Таким образом, рассылка общей последовательности эквивалентна нескольким циклам консенсуса (каждое принятое решение соответствует доставке одного сообщения).

## Репликация с одним ведущим узлом и консенсус

В главе 5 обсуждалась репликация с одним ведущим узлом. Разве это не то же самое, что рассылка общей последовательности? Почему в главе 5 нам не пришлось беспокоиться о консенсусе?

Ответ сводится к выбору ведущего узла. Если он выбирается вручную и настраивается людьми из операционного отдела, то, по существу, у вас уже есть «консенсусный алгоритм» диктаторского типа. Но при выходе этого узла из строя система станет недоступной для записи, пока операторы вручную не назначат ведущим другой узел.

В некоторых базах данных выполняется автоматический выбор ведущего узла и переход на другой ресурс. Это приближает нас к отказоустойчивости рассылки общей последовательности и, соответственно, к достижению консенсуса.

### Нумерация периодов и кворумы

Все консенсусные протоколы основаны на использовании ведущего узла в той или иной форме, но не гарантируют, что он уникален. Вместо этого они предлагают более слабую гарантию: протоколы определяют номер периода (в Paxos называемый номером бюллетеня, в Viewstamped Replication — номером просмотра, в Raft — номером термина) и гарантируют, что в каждый период ведущий узел уникален.

Прежде чем ведущий узел получает право принимать решения, он должен проверить, нет ли другого такого узла с более высоким номером периода. Он должен собирать голоса кворума узлов. Для каждого решения, которое ведущий узел намерен принять, он должен отправить предлагаемое значение другим узлам и дождаться, пока кворум узлов согласится с этим предложением.

## Ограничения консенсуса

Алгоритмы консенсуса являются огромным прорывом для распределенных систем, но за их преимущества приходится расплачиваться:

- **Процесс голосования** является своего рода синхронной репликацией, что может снижать производительность
- **Консенсусные системы всегда требуют строгого большинства**: нужно минимум три узла, чтобы выдержать один сбой, или минимум пять узлов, чтобы выдержать два
- **Большинство консенсусных алгоритмов предполагает, что в голосовании участвует фиксированный набор узлов**: нельзя просто добавить или удалить узел в кластере
- **Для обнаружения узлов, вышедших из строя, консенсусные системы обычно полагаются на время ожидания**: в системах с сильно различающимися сетевыми задержками часто бывает так, что узел ошибочно предполагает, будто ведущий вышел из строя
- **Иногда консенсусные алгоритмы особенно чувствительны к сетевым проблемам**: могут попасть в ситуацию, когда руководящая роль непрерывно кочует между двумя узлами

## Сервисы членства и координации

Проекты, подобные ZooKeeper или etcd, часто описываются как «распределенные хранилища типа "ключ — значение"» или «сервисы координации и настройки». Они предназначены для хранения небольших объемов данных, которые полностью помещаются в памяти, и реплицируются по всем узлам с помощью отказоустойчивого алгоритма рассылки общей последовательности.

### Функции ZooKeeper/etcd

- **Линеаризуемые атомарные операции**: используя атомарную операцию сравнения с присвоением, можно реализовать блокировку
- **Общая последовательность операций**: каждая операция получает монотонно возрастающий идентификатор транзакции (zxid в ZooKeeper), который может служить ограждающим маркером
- **Обнаружение сбоев**: клиенты поддерживают длительные сеансы, и если передача тактов прекращается на время, превышающее время ожидания сеанса, ZooKeeper объявляет сеанс прерванным
- **Изменение уведомлений**: клиент может следить за изменениями в других узлах, не совершая частые опросы

### Использование сервисов координации

Примеры ситуаций, где модель ZooKeeper/Chubby эффективна:
- **Выбор ведущего узла**: несколько экземпляров процесса или сервиса, один из которых должен быть выбран в качестве ведущего
- **Распределение нагрузки между узлами**: решение, какому узлу будет назначен тот или иной раздел базы данных, потоков сообщений или хранилища файлов

Задачи такого типа могут быть решены с помощью разумного использования атомарных операций, эфемерных узлов и уведомлений в ZooKeeper.

