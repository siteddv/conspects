Узлы, хранящие копии базы данных, называются репликами. Основной задачей является обеспечение согласованности данных во всех репликах, что достигается с помощью **репликации с ведущим узлом** (leader-based replication).

В этой модели одна реплика становится ведущей (leader), принимая запросы на запись от клиентов и записывая данные в своё хранилище. Затем ведущий отправляет журнал изменений (replication log) всем ведомым узлам (followers), которые обновляют свои копии базы данных.

![[22. Replication with leading node.png]] [22. Replication with leading node.png](22. Replication with leading node.png.md)

Чтение данных возможно как с ведущего узла, так и с ведомых, но записи разрешены только на ведущем. Этот метод поддерживается многими реляционными и нереляционными базами данных, такими как PostgreSQL, MySQL и MongoDB.

### Синхронная и асинхронная репликация

Важным аспектом работы реплицируемых систем является выбор между синхронной и асинхронной репликацией. При синхронной репликации ведущий узел дожидается подтверждения от ведомого узла перед тем, как сообщить клиенту об успешном обновлении данных. Это обеспечивает актуальность данных, но может замедлить систему, если ведомый узел не отвечает. Асинхронная репликация, наоборот, позволяет ведущему узлу отправлять изменения ведомым без ожидания подтверждения, что увеличивает скорость операций, но может привести к потере данных при сбое ведущего узла.

![[23. Async and sync replication.png]] [23. Async and sync replication.png](23. Async and sync replication.png.md)

На практике часто используется полусинхронная конфигурация, где один из ведомых узлов синхронный, а остальные асинхронные. Это позволяет гарантировать наличие актуальных данных на хотя бы двух узлах. Полностью асинхронные системы удобны при наличии множества ведомых узлов, но могут привести к потере данных в случае сбоя ведущего узла.

Исследователи продолжают изучать методы, которые обеспечивают сохранность данных и хорошую производительность, такие как цепная репликация. В данной главе акцент сделан на более простых и широко используемых формах репликации в базах данных.

### Создание новых ведомых узлов

При создании новых ведомых узлов для увеличения числа реплик или замены сбойных важно обеспечить согласованность данных. Простое копирование данных не подходит, поскольку база постоянно обновляется. Вместо этого процесс включает следующие шаги:

1. Создание согласованного снимка состояния базы данных ведущего узла без блокировки системы, используя встроенные функции или сторонние утилиты (например, innobackupex для MySQL).
2. Копирование этого снимка на новый ведомый узел.
3. Подключение ведомого узла к ведущему и запрос изменений, произошедших с момента создания снимка, используя позицию в журнале репликации (например, регистрационный номер транзакции в PostgreSQL).

Этот процесс может варьироваться в зависимости от системы: некоторые базы данных предлагают автоматизированные решения, в то время как другие требуют ручных действий от администратора.
### Перебои в обслуживании узлов

Для обеспечения высокой доступности при репликации с одним ведущим узлом важно минимизировать влияние отказов или технического обслуживания узлов. Система должна продолжать функционировать, позволяя при этом перезагрузку отдельных узлов без простоя.

### Отказ ведомого узла: наверстывающее восстановление

Каждый ведомый узел хранит журнал изменений, полученных от ведущего узла. При сбое или перезагрузке ведомый узел может восстановить работу, обращаясь к своему журналу. Он подключается к ведущему и запрашивает все изменения, произошедшие за время его недоступности, что позволяет ему синхронизироваться и продолжать обработку данных.

### Отказ ведущего узла: восстановление после отказа

Восстановление после отказа (failover) — это процесс, который осуществляется при сбое ведущего узла в распределенной системе. Он включает в себя несколько этапов:

1. **Установление отказа**: Система определяет, что ведущий узел недоступен, обычно через механизм превышения времени ожидания. Если узел не отвечает в течение установленного времени (например, 30 секунд), он считается неработоспособным.
    
2. **Выбор нового ведущего узла**: Это может быть сделано через процесс «выборов», где новый ведущий выбирается среди оставшихся реплик, либо с помощью заранее назначенного узла-контроллера. Оптимальным кандидатом считается реплика с самыми свежими данными, чтобы минимизировать потери.
    
3. **Настройка системы**: Клиенты должны перенастроиться на новый ведущий узел. Если старый узел возвращается в сеть, он должен осознать, что его статус изменился на ведомый.
    

Процесс восстановления связан с множеством проблем. Например, при асинхронной репликации новый ведущий может не получить все записи от старого, что приводит к потенциальным конфликтам. В одном случае на GitHub ведомый узел с устаревшими данными был повышен до ведущего, что вызвало несогласованность данных между MySQL и Redis.

Также существует риск «разделения вычислительных мощностей», когда два узла считают себя ведущими. Это может привести к потерям данных без эффективного механизма разрешения конфликтов. Необходимо тщательно проектировать систему, чтобы избежать таких ситуаций.

Определение времени ожидания для объявления ведущего узла недоступным также критично: слишком долгое ожидание увеличивает время восстановления, в то время как слишком короткое может вызвать ложные срабатывания. Поэтому некоторые администраторы предпочитают ручное восстановление, несмотря на возможности автоматизации. Эти вопросы являются фундаментальными проблемами распределенных систем и будут рассмотрены подробнее в следующих главах.

### Операторная репликация

В простейшем случае репликация осуществляется так: ведущий узел записывает каждый выполненный запрос (оператор) в журнал и пересылает его ведомым узлам. Команды SQL (INSERT, UPDATE, DELETE) выполняются на всех репликах так, как если бы они были получены от клиента.

Однако этот подход имеет недостатки:

**Недетерминированные функции**: Например, NOW() или RAND() могут генерировать разные значения на разных репликах.

**Порядок выполнения**: Операторы, зависящие от данных или использующие автоматически увеличиваемые значения, должны выполняться в строгом порядке, иначе результаты будут различаться.

 **Побочные действия**: Триггеры и хранимые процедуры могут вести себя по-разному на репликах, если не детерминированы.

Ведущий узел может заменять недетерминированные функции фиксированными значениями, но из-за множества граничных случаев предпочитаются другие методы репликации. Операторная репликация использовалась в MySQL до версии 5.1, сейчас по умолчанию применяется построчная репликация. VoltDB использует операторную репликацию с требованием детерминизма транзакций.

### Перенос журнала упреждающей записи (WAL)

В главе 3 обсуждалось, как подсистемы хранения представляют данные на диске, и выяснилось, что практически все данные записываются в журнал.

**Журналированная подсистема хранения**: В этом случае журнал является основным местом хранения информации, сжимаемой и очищаемой в фоновом режиме.

**B-деревья**: Здесь все изменения сначала записываются в журнал, что позволяет вернуть индекс в согласованное состояние после сбоя.

Журнал представляет собой последовательность байтов, содержащую результаты всех операций записи. Этот же журнал может использоваться для создания реплик на других узлах: ведущий узел отправляет журнал по сети ведомым узлам, которые, обрабатывая его, создают точные копии структур данных.

Метод репликации, основанный на журнале, используется в PostgreSQL и Oracle, но имеет недостаток: он описывает данные на низком уровне, что может усложнять совместимость между версиями СУБД. Это ограничение влияет на возможность обновления ПО без простоя: если протокол репликации не поддерживает разные версии, обновления требуют временного отключения системы.

### Логическая (построчная) журнальная репликация

Альтернативой традиционному журналу является использование логического журнала (logical log), который отделяет журнал репликации от внутренней структуры подсистемы хранения.

Логический журнал для реляционных баз данных представляет собой последовательность строк, описывающих операции записи на уровне строк:

* При вставке строки журнал включает новые значения всех столбцов.
* При удалении строки он содержит информацию для идентификации удаляемой строки, обычно первичный ключ или старые значения всех столбцов.
* При обновлении строки журнал фиксирует идентификатор обновляемой строки и новые значения измененных столбцов.

Для транзакций, затрагивающих несколько строк, генерируются несколько записей, завершающихся записью о фиксации транзакции. Такой подход используется в бинарном журнале MySQL.

Логический журнал проще поддерживать с точки зрения совместимости, позволяя различным версиям СУБД работать на ведущем и ведомых узлах. Он также удобен для синтаксического разбора внешними приложениями, что важно для передачи данных во внешние системы, например, для создания складов данных. Этот процесс называется захватом изменений данных (change data capture).

### Триггерная репликация

Подходы к репликации, описанные ранее, часто реализуются в СУБД без участия кода приложения, что подходит для многих случаев. Однако иногда требуется большая гибкость, например, при репликации подмножества данных, миграции между различными типами БД или при необходимости разрешения конфликтов.

Для этого можно использовать инструменты, такие как Oracle GoldenGate, которые позволяют приложению читать данные из журнала БД. Также доступны триггеры и хранимые процедуры. Триггеры автоматически запускают пользовательский код при изменении данных и могут записывать изменения в отдельную таблицу для дальнейшей обработки внешними процессами, что позволяет применять необходимую бизнес-логику.

Хотя накладные расходы при триггерной репликации выше, а также она более подвержена ошибкам и ограничена по сравнению с встроенной репликацией, её гибкость может оказаться полезной в определённых сценариях.
