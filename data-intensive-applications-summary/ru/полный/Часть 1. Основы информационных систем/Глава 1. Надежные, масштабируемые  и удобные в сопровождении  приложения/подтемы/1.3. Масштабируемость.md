Масштабируемость — это способность системы справляться с возросшей нагрузкой. Она требует рассмотрения вариантов расширения ресурсов для эффективной работы при увеличении пользователей или данных.
### Описание нагрузки
Для анализа нагрузки на систему важно сначала описать текущие параметры, такие как количество запросов к веб-серверу или активные пользователи. Рассмотрим пример Twitter, где две основные операции — публикация твита и просмотр домашней ленты — имеют разные характеристики нагрузки.

Первый подход к реализации ленты состоит в том, что при публикации твита новый твит добавляется в общий набор записей. При запросе домашней ленты выполняется поиск твитов всех подписанных пользователей и их сортировка. Этот метод сталкивается с проблемами при высокой частоте чтения, поскольку он требует значительных вычислительных ресурсов.

![[2. twitter_feed_1.png]] [2. twitter_feed_1.png](2. twitter_feed_1.png.md)

Второй подход включает кэширование домашней ленты для каждого пользователя. При публикации твита информация отправляется всем подписчикам и добавляется в их кэши. Это делает чтение домашних лент более эффективным, но увеличивает нагрузку при записи, поскольку один твит может создавать миллионы записей в кэше. Twitter первоначально использовал первый подход, но переключился на второй, чтобы справиться с нагрузкой.

![[3. twitter_feed_2.png]] [3. twitter_feed_2.png](3. twitter_feed_2.png.md)

Со временем Twitter начал комбинировать оба метода, сохраняя основные записи для обычных пользователей и применяя первый подход для знаменитостей с большим количеством подписчиков. Это обеспечивает оптимальную производительность для разных типов пользователей.

### Описание производительности

Производительность системы можно оценить по двум основным аспектам: как изменится производительность при увеличении нагрузки при неизменных ресурсах и какое увеличение ресурсов требуется для поддержания текущей производительности. В системах пакетной обработки данных, таких как Hadoop, главной метрикой является пропускная способность, которая показывает количество обработанных записей в секунду. В онлайн-системах более важным показателем становится время отклика — интервал от отправки запроса до получения ответа.

Существует важное различие между временем ожидания (latency) и временем отклика (response time). Время отклика включает время, затраченное на обработку запроса, а также задержки, возникающие в процессе передачи данных по сети и ожидания в очереди. Время ожидания же измеряет только тот период, в течение которого запрос ожидает обработки. Из-за неравномерной обработки запросов и других факторов, таких как потеря пакетов или сборка мусора, время отклика может варьироваться, что делает его распределением значений, а не фиксированным числом.

Для оценки времени отклика часто используется медиана, или 50-й процентиль (p50), которая дает представление о том, сколько времени обычно ожидают пользователи. Однако более информативными могут быть и более высокие процентили, такие как 95-й (p95) или 99-й (p99), которые показывают, сколько процентов запросов обрабатывается быстрее определенного порогового значения. Например, значение p95 может означать, что 95% запросов обрабатываются быстрее 1,5 секунд. Это важно, так как низкие значения верхних процентилей непосредственно влияют на пользовательский опыт.

![[4. Load graph.png]] [4. Load graph.png](4. Load graph.png.md)

Для компаний, таких как Amazon, критично учитывать высокие процентили времени отклика, поскольку именно пользователи с большими объемами данных чаще всего испытывают задержки. Например, увеличение времени отклика на 100 мс может снизить продажи на 1%. При этом оптимизация времени отклика на 99.99-й процентиль (p999) может быть слишком дорогостоящей и неэффективной, так как её улучшение может принести минимальные выгоды.

При этом задержки в очереди запросов могут стать причиной повышения времени отклика на верхних процентилях. Сервер может одновременно обрабатывать лишь ограниченное количество заданий, и даже небольшое количество медленных запросов может привести к блокировке последующих. Это явление называется блокировкой головы очереди, где быстрые запросы все равно терпят задержки из-за ожидания завершения медленных.

![[5. Load bottleneck.png]] [5. Load bottleneck.png](5. Load bottleneck.png.md)

Для эффективного нагрузочного тестирования необходимо, чтобы клиентская сторона генерировала нагрузку, отправляя запросы независимо от времени отклика. Если клиент будет дожидаться завершения предыдущего запроса, это приведет к искажению результатов, так как в реальных условиях такая ситуация не возникает.

Таким образом, для обеспечения высокой производительности системы и удовлетворенности пользователей важно не только отслеживать средние значения времени отклика, но и уделять внимание распределению значений, особенно верхним процентилям, которые показывают, как быстро система справляется с наиболее сложными запросами.

### Процентили на практике

Верхние процентили времени отклика особенно важны в прикладных сервисах, так как даже один медленный вызов может замедлить выполнение запроса конечного пользователя. Это приводит к усилению «хвостового» времени ожидания, особенно когда запрос требует множество параллельных вызовов. Для мониторинга целесообразно регулярно вычислять процентили, используя скользящее окно за последние 10 минут. Наивная реализация включает сортировку списка времен отклика, но существуют более эффективные алгоритмы, такие как forward decay и t-digest. Учитывайте, что усреднение процентилей является математически некорректным; лучше агрегировать данные через гистограммы.

### Как справиться с нагрузкой

При изучении масштабируемости важно понимать, как сохранить хорошую производительность при увеличении нагрузки. Архитектура, подходящая для текущего уровня нагрузки, может не справиться с десятикратным увеличением. Существует два основных подхода к масштабированию: вертикальное (переход на более мощные машины) и горизонтальное (распределение нагрузки по нескольким меньшим машинам).

Автоматическое масштабирование позволяет системам адаптироваться к изменяющейся нагрузке, в то время как ручное масштабирование требует анализа производительности. Преобразование систем с сохранением состояния в распределенные может быть сложным, и до недавнего времени базы данных часто держали на одном узле. Однако с развитием инструментов распределенные системы могут стать стандартом даже для менее требовательных приложений.

Архитектура масштабируемых систем зависит от специфики приложения и требований, таких как объем данных и паттерны доступа. Хорошая масштабируемая для конкретного приложения архитектура базируется на допущениях о том, какие операции будут выполняться часто, а какие — редко, то есть на параметрах нагрузки Хорошая архитектура основывается на правильных допущениях о нагрузке, чтобы избежать неэффективности в будущем.