MapReduce — это всего лишь одна из многих возможных моделей программирования распределенных систем. В зависимости от объема данных, их структуры и типа обработки другие инструменты могут оказаться более эффективными для выполнения вычислений.

## Материализация промежуточного состояния

В MapReduce каждая задача не зависит от других задач. Главными точками соприкосновения задачи с внешним миром являются ее каталоги входных и выходных данных в распределенной файловой системе. Чтобы выходные данные одной задачи стали входными для другой, нужно сделать выходной каталог первой задачи входным каталогом второй.

**Проблемы материализации:**
- Задача MapReduce запускается только после завершения всех операций предыдущих задач, в то время как процессы, объединенные в конвейер Unix, запускаются одновременно
- Функции сопоставления часто являются избыточными: они просто читают тот же файл, который был только что написан функцией сжатия
- Сохранение промежуточного состояния в распределенной файловой системе означает репликацию этих файлов на нескольких узлах, что часто бывает избыточным для таких временных данных

**Конвейеры Unix:**
- Вместо того чтобы полностью материализовать промежуточное состояние, конвейеры передают поток выходных данных на вход постепенно, применяя только небольшой буфер в памяти

## Подсистемы потока данных

Чтобы устранить проблемы с MapReduce, было разработано несколько новых механизмов для выполнения распределенных пакетных вычислений: Spark, Tez и Flink. Они сильно различаются по архитектуре, но имеют одну общую черту: весь рабочий процесс рассматривается как одна задача, без разделения на независимые подзадачи.

**Варианты передачи данных между операторами:**
- Повторное секционирование и сортировка записей по ключу, как на этапе перетасовки в MapReduce
- Секционирование нескольких наборов входных данных по одному и тому же принципу, но без сортировки (распределенное хеш-объединение)
- Для объединений с хеш-трансляцией один и тот же набор выходных данных от заданного оператора может быть отправлен на все разделы оператора объединения

**Преимущества подсистем потока данных:**
- Затратные вычисления, такие как сортировка, выполняются только там, где это действительно необходимо
- Не выполняется лишних сопоставлений, так как работа, выполняемая функциями сопоставления, часто может быть включена в предыдущий оператор сжатия
- Планировщик знает, какие данные и где требуются, и может выполнить локальную оптимизацию
- Промежуточное состояние между операторами сохраняется в памяти или записывается на локальный диск
- Операторы начинают работу сразу, как только готовы их входные данные
- Существующие процессы Java Virtual Machine (JVM) можно многократно использовать для запуска новых операторов

**Отказоустойчивость:**
- В Spark, Flink и Tez промежуточное состояние не записывается в HDFS
- Для устойчивости к отказам используется повторное вычисление: если на компьютере происходит сбой и промежуточное состояние на нем потеряно, то оно повторно вычисляется по другим данным, которые еще доступны
- В Spark задействуется абстракция гибкого распределенного набора данных (resilient distributed dataset, RDD), которая позволяет отслеживать происхождение данных
- Flink проверяет состояние оператора, что позволяет возобновить его работу, если в процессе его выполнения произойдет сбой

**Детерминированность:**
- При повторной обработке данных важно знать, является ли вычисление детерминированным
- Если оператор выполняется повторно, а пересчитанные данные не совпадают с предыдущими, то следующим операторам будет очень трудно устранить противоречия
- Во избежание каскадных ошибок лучше сделать операторы детерминированными

## Графы и итеративная обработка

Многие графовые алгоритмы описываются как последовательность перемещений по ребрам, и одна вершина соединяется с другой соседней для распространения некоторой информации. Так повторяется до тех пор, пока не будет выполнено некое условие.

**Проблема с MapReduce:**
- Идея «повторять до завершения» не может быть реализована в обычной MapReduce, поскольку там выполняется только один проход по данным
- Реализация в MapReduce часто очень неэффективна, потому что система всегда будет считывать весь набор входных данных и каждый раз создавать совершенно новый выходной набор

**Модель обработки Pregel:**
- Модель синхронных параллельных вычислений (bulk synchronous parallel, BSP)
- Реализована в Apache Giraph, Spark GraphX API и Flink Gelly API
- Одна вершина может «отправить сообщение» другой, и эти сообщения обычно отправляются по ребрам графа
- На каждой итерации функция вызывается для каждой вершины, передавая ей все адресованные ей сообщения
- Вершина сохраняет в памяти свое состояние до следующей итерации

**Отказоустойчивость в Pregel:**
- Периодическая проверка состояния всех вершин в конце итерации — их полное состояние записывается в долговременное хранилище
- Если узел выходит из строя, то самым простым решением является откат всей обработки графа до последней контрольной точки и повторная обработка
- В случае детерминированного алгоритма и регистрации сообщений можно также выборочно восстановить только тот раздел, который был потерян

**Параллельная обработка:**
- Вершине не нужно знать, на какой физической машине она выполняется
- За секционирование графа отвечает система
- Графовые алгоритмы часто порождают много межмашинных коммуникационных издержек
- Если граф помещается в памяти одного компьютера, вполне вероятно, что одномашинный алгоритм будет работать быстрее, чем распределенный пакетный процесс

## API и языки высокого уровня

**Высокоуровневые интерфейсы:**
- Языки более высокого уровня и API, такие как Hive, Pig, Cascading и Crunch, стали популярными, поскольку программировать задачи вручную в MapReduce — довольно трудоемкий процесс
- В Spark и Flink также имеются собственные потоковые API высокого уровня
- Эти потоковые API обычно используют для описания вычислений структурные блоки реляционного стиля: объединение наборов данных, группировку кортежей по ключу, фильтрацию, агрегирование

**Переход к декларативным языкам запросов:**
- Преимущество объединений в качестве реляционных операторов заключается в том, что система может анализировать свойства входных данных и автоматически определять, какой алгоритм объединения будет наиболее подходящим
- В Hive, Spark и Flink есть оптимизаторы запросов по вычислительным затратам, способные изменить порядок объединений, чтобы свести к минимуму количество промежуточных состояний
- При декларативном описании простых операций фильтрации и сопоставления оптимизатор запросов может задействовать преимущества столбцового хранения данных и прочитать с диска только нужные столбцы

**Свобода выбора кода:**
- В основе MapReduce была заложена идея обратного вызова функций: для каждой записи или группы записей вызывается пользовательская функция, которая может выполнять произвольный код
- Преимущество такого подхода состоит в возможности применения обширной экосистемы существующих библиотек
- Системы пакетной обработки сохраняют гибкость вследствие возможности расширения за счет произвольного кода и чтения данных в произвольных форматах

**Специализация для разных областей:**
- Традиционно базы данных MPP удовлетворяли потребности бизнес-аналитики и бизнес-отчетности
- Еще одной областью, приобретающей все большее значение, являются статистические и численные алгоритмы, используемые в приложениях машинного обучения
- Появляются многоразовые реализации: например, в Mahout созданы алгоритмы машинного обучения на базе MapReduce, Spark и Flink

