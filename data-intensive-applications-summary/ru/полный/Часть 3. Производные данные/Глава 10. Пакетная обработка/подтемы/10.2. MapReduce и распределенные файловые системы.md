Модель программирования MapReduce подобна инструментам Unix, но распространяется на много компьютеров — потенциально на тысячи. Как и в случае с Unix, это довольно примитивный, грубый, но удивительно эффективный инструмент.

## Основная идея MapReduce

Задача MapReduce подобна процессу Unix: принимает один или несколько потоков ввода и производит один или несколько потоков вывода. Как и большинство инструментов Unix, задача MapReduce обычно не изменяет входные данные и не имеет побочных эффектов — только генерирует выходные. Последние записываются один раз, последовательно.

Вместо использования стандартного ввода и вывода, задачи MapReduce читают и записывают файлы в распределенной файловой системе. В реализации Hadoop MapReduce эта файловая система называется HDFS (Hadoop Distributed File System).

## Распределенная файловая система

HDFS — это распределенная файловая система, которая создает одну большую файловую систему, использующую дисковое пространство всех компьютеров в кластере. Центральный сервер, называемый NameNode, отслеживает, на каком компьютере хранятся те или иные блоки файлов.

**Репликация:**
- Файловые блоки дублируются на нескольких машинах для отказоустойчивости
- Репликация может означать просто несколько копий одних и тех же данных, или схему удаляющего кодирования (коды Рида — Соломона)

**Масштабируемость:**
- HDFS хорошо масштабируется: самые крупные системы насчитывают десятки тысяч машин общей емкостью хранения данных в сотни петабайт
- Это стало возможным благодаря низкой стоимости хранения данных на обычном аппаратном обеспечении

## Выполнение задач в MapReduce

MapReduce — среда разработки, позволяющая писать код для обработки больших наборов данных в распределенной файловой системе. Процесс обработки данных в MapReduce состоит из четырех этапов:

1. **Прочитать набор входных файлов и разделить их на записи** — реализуется синтаксическим анализатором формата ввода
2. **Вызвать функцию сопоставления** — извлечь ключ и значение для каждой входной записи
3. **Отсортировать все пары «ключ — значение» по ключу** — выполняется в MapReduce по умолчанию
4. **Вызвать функцию сжатия** — для всех отсортированных пар «ключ — значение»

### Функции обратного вызова

Чтобы создать задачу MapReduce, необходимо реализовать две функции обратного вызова:

**Сопоставление (Map):**
- Вызывается один раз для каждой входной записи
- Задача — извлечь ключ и значение записи
- Для каждого набора входных данных может быть сгенерировано любое количество пар «ключ — значение»
- При переходе от одной входной записи к следующей никакие промежуточные состояния не сохраняются, каждая запись обрабатывается независимо

**Сжатие (Reduce):**
- Среда разработки MapReduce принимает пары «ключ — значение», созданные функцией сопоставления
- Объединяет все значения, соответствующие одному ключу
- Вызывает для каждой такой группы значений функцию сжатия
- Функция сжатия может создавать выходные записи

## Распределенные вычисления в MapReduce

Основное отличие MapReduce от конвейеров команд Unix заключается в том, что в MapReduce можно распараллеливать вычисления на нескольких машинах, и для этого не требуется писать код, явно реализующий параллелизм.

**Принцип «где данные, там вычисления»:**
- Планировщик задач MapReduce старается запустить функцию сопоставления на каждом компьютере, где хранится копия входного файла
- Это сохраняет копию входного файла в сети, уменьшая нагрузку на сеть и увеличивая локальность

**Процесс выполнения:**
1. Планировщик копирует код приложения на соответствующие машины
2. Запускает задачу сопоставления и начинает чтение входного файла
3. Результатом сопоставления является набор из пар «ключ — значение»
4. Этап сжатия также секционирован между разными машинами
5. Для распределения пар «ключ — значение» используется хеш ключей

**Перетасовка (Shuffle):**
- Процесс секционирования по принадлежности к конкретной функции сжатия, сортировки и копирования разделов данных с этапа сопоставления на этап сжатия называется перетасовкой
- Каждая задача сопоставления разбивает свой результат на части для сжатия на основе хеша ключей
- Каждая такая секция записывается в отсортированный файл на локальном диске
- Функции сжатия подключаются к функциям сопоставления и загружают файлы с отсортированными парами «ключ — значение»

## Потоки MapReduce

Круг проблем, решаемых с помощью одной задачи MapReduce, ограничен. Поэтому задачи MapReduce часто объединяются в потоки, где выходные данные одной задачи становятся входными для следующей.

**Особенности потоков:**
- В среде разработки Hadoop MapReduce нет специальной поддержки рабочих процессов
- Цепочки создаются неявно, по имени каталога: первая задача записывает выходные данные в выбранный каталог HDFS, следующая читает входные данные из него
- С точки зрения MapReduce это две независимые задачи

**Планировщики потоков:**
- Для обработки зависимостей между выполнением задач были разработаны различные планировщики потоков: Oozie, Azkaban, Luigi, Airflow и Pinball
- Высокоуровневые инструменты для Hadoop: Pig, Hive, Cascading, Crunch и FlumeJava

## Объединение и группировка на этапе сжатия

Во многих наборах данных реализованы взаимосвязи между записями. Объединения необходимы в тех случаях, когда некий код должен иметь доступ к записям, принадлежащим обеим сторонам ассоциации.

**Объединение с сортировкой слияния:**
- Функции сопоставления извлекают ключ (например, ID пользователя) из каждой входной записи
- Среда разработки MapReduce сортирует пары «ключ — значение» и разделяет их по ключам
- Все записи с одинаковым ключом идут подряд и поступают на вход функции сжатия
- Функция сжатия может легко выполнить логику объединения, обрабатывая все записи для определенного ключа за один проход

**Преимущества:**
- Функция сжатия хранит в памяти только одну запись пользователя за раз
- Никогда не делает запросы по сети
- Все необходимые данные подобраны заранее
- Сжатие может быть реализовано в виде простого однопотокового кода

**GROUP BY:**
- Группировка записей по заданному ключу работает аналогично объединениям
- Все записи с одним и тем же ключом объединяются в группу
- В каждой группе часто выполняется какое-либо обобщение (подсчет, суммирование, выбор k первых записей)

**Обработка асимметрии:**
- Если данных, связанных с одним ключом, очень много (горячие ключи), шаблон «собрать все записи с одним ключом в одном месте» ломается
- Методы компенсации: асимметричное объединение, сегментированное объединение, двухэтапная группировка

## Объединения на этапе сопоставления

Алгоритмы объединения, описанные выше, выполняют фактическое объединение в функциях сжатия и называются объединениями на этапе сжатия. Однако можно выполнить объединение и на этапе сопоставления.

**Широковещательное объединение по хешу:**
- Применяется в случае, когда большой набор данных объединяется с малым
- Малый набор данных должен полностью помещаться в памяти в каждой функции сопоставления
- Функция сопоставления сначала считывает малый набор данных в хеш-таблицу, затем сканирует большой набор и находит совпадения

**Секционированное хеш-объединение:**
- Если входные данные для объединения разделены одинаково, то объединение по хешу может выполняться для каждого раздела в отдельности
- Каждая функция сопоставления загружает в хеш-таблицу меньшее количество данных

**Объединение слиянием на этапе сопоставления:**
- Если входные наборы данных не только разделены одинаково, но и сортируются по одному ключу, то применяется объединение слиянием
- Функция сопоставления может выполнять ту же операцию слияния, которая обычно выполнялась на этапе сжатия

## Выходные данные пакетных потоков

**Построение поисковых индексов:**
- Пакетный процесс — очень эффективный способ построения индекса
- Функции сопоставления разбивают набор документов, каждая функция сжатия строит индекс для своего раздела
- Индексные файлы записываются в распределенную файловую систему

**Хранилища пар «ключ — значение» как выходные данные:**
- Результатом выполнения пакетных задач часто является база данных
- Для создания файлов базы данных в задачах MapReduce используются такие хранилища типа «ключ — значение», как Voldemort, Terrapin, ElephantDB и HBase
- Эти хранилища предназначены только для чтения: файлы могут быть записаны лишь один раз, при выполнении пакетной задачи, и затем не изменяются

**Философия выходных данных пакетного процесса:**
- Входные данные неизменяемы, выходные предназначены служить входными для другой программы
- При ошибке в коде можно вернуться к предыдущей версии кода и повторить задачу
- Следствием такой легкости отката является то, что разработка функций выполняется быстрее
- Один и тот же набор файлов может использоваться как входные данные для различных задач

## Сравнение Hadoop и распределенных баз данных

**Разнообразие хранилищ данных:**
- Базы данных требуют структурировать данные в соответствии с определенной моделью
- Файлы в распределенной файловой системе — это просто последовательности байтов, которые могут быть записаны с помощью любой модели данных
- Система Hadoop открыла возможность записывать в HDFS любые данные и только потом выяснять, как их обрабатывать (подход «схема при чтении»)

**Разнообразие моделей обработки:**
- Базы данных MPP — монолитные, тесно интегрированные части программного обеспечения
- Система MapReduce позволяет инженерам легко запускать разработанный ими код для больших наборов данных
- Можно построить систему выполнения SQL-запросов поверх MapReduce (Hive), но можно также написать много других форм пакетных процессов

**Проектирование на случай частых сбоев:**
- MapReduce допускает ошибки на этапах сопоставления или сжатия — соответствующая операция просто совершается повторно
- Активно используется запись данных на диск — отчасти для большей отказоустойчивости, отчасти из предположения, что набор данных слишком велик, чтобы поместиться в памяти
- В Google вероятность того, что задача MapReduce будет прервана с целью освободить ресурсы для процесса с более высоким приоритетом, составляет примерно 5 %
- Именно поэтому система MapReduce рассчитана на частые неожиданные прерывания задач

