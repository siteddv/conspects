Программы работают с данными в двух представлениях: в памяти и в виде последовательности байтов. В памяти данные хранятся в оптимизированных структурах (объекты, списки и т. д.), удобных для CPU. При записи или передаче данные кодируются в последовательность байтов (например, JSON). Процесс преобразования из памяти в байтовую последовательность называется кодированием (или сериализацией), а обратный процесс — декодированием (или десериализацией). В книге используется термин «кодирование», чтобы избежать путаницы. Существует множество библиотек и форматов для этой задачи.

### Форматы, ориентированные на конкретные языки

Во многих языках программирования есть встроенные средства кодирования объектов в байтовые последовательности (например, Java — java.io.Serializable, Ruby — Marshal, Python — pickle). Эти библиотеки удобны, но имеют серьезные недостатки:

**Языковая привязка:** Кодирование зависит от конкретного языка, что затрудняет интеграцию с другими системами.

**Безопасность:** Декодирование может создавать экземпляры произвольных классов, что открывает возможности для атак.

**Контроль версий:** Многие библиотеки игнорируют проблемы совместимости, что усложняет поддержку старых и новых версий.

**Эффективность:** Производительность и объем памяти часто не учитываются, что делает встроенные средства неэффективными.

Из-за этих проблем использование таких средств для долгосрочных целей обычно нецелесообразно.

### JSON, XML и двоичные типы данных

Стандартизованные форматы кодирования, такие как JSON и XML, широко поддерживаются, но имеют свои недостатки. XML критикуют за "многословность", а JSON популярен благодаря встроенной поддержке в браузерах и простоте. CSV также распространен, но имеет ограниченные возможности.

Все три формата сталкиваются с проблемами кодирования чисел: в XML и CSV трудно различить числа и строки, в то время как JSON не поддерживает точность для целых и дробных чисел. Проблема больших чисел (более 2^53) в JavaScript также актуальна. В API Twitter идентификаторы твитов возвращаются и как JSON-числа, и как строки, чтобы избежать неточностей.

JSON и XML поддерживают строки в кодировке Unicode, но не двоичные строки, что требует кодирования двоичных данных через Base64, увеличивая объем на 33%. Оба формата поддерживают схемы, что усложняет их использование. CSV не имеет схемы, что затрудняет обработку изменений в данных.

Несмотря на недостатки, JSON, XML и CSV остаются популярными для обмена данными между предприятиями, поскольку главное — согласие о формате.

Для внутренних данных можно выбирать более эффективные двоичные форматы, такие как MessagePack и BSON. Эти форматы расширяют типы данных, но не задают схемы, поэтому все имена полей должны быть включены в закодированные данные. Например, в MessagePack объект из JSON занимает 66 байт, что меньше 81 байта текстового JSON. Однако вопрос о потере удобочитаемости ради экономии места остается открытым.

### Thrift и Protocol Buffers

Apache Thrift и Protocol Buffers (protobuf) — это библиотеки двоичного кодирования, разработанные Facebook и Google соответственно, обе открыты с 2007–2008 годов. Они требуют наличия схемы для кодируемых данных. Пример схемы для библиотеки Thrift включает структуру Person, которая определяет поля userName, favoriteNumber и interests. В Protocol Buffers аналогичная структура выглядит схожим образом.

Обе библиотеки предоставляют утилиты для генерации кода на разных языках программирования, что упрощает процесс кодирования и декодирования. В Thrift есть два двоичных формата: BinaryProtocol и CompactProtocol. BinaryProtocol занимает 59 байт, в то время как CompactProtocol упаковывает данные в 34 байта за счет сжатия типов полей и использования переменной длины для целых чисел.

Protocol Buffers кодируют те же данные в 33 байта, используя схожие методы упаковки. Важно отметить, что в двоичных данных не фиксируется обязательность полей; пометка required лишь активирует проверку на этапе выполнения, что помогает в отладке.

### Теги полей и эволюция схемы

Эволюция схемы в библиотеках Thrift и Protocol Buffers позволяет изменять схемы, сохраняя совместимость. Каждое поле определяется уникальным номером тега, что делает их критически важными для интерпретации закодированных данных. Можно изменять названия полей, но теги менять нельзя, иначе это повредит существующим данным.

Новые поля могут добавляться с новыми номерами тегов, позволяя старому коду игнорировать их, что обеспечивает прямую совместимость. Однако новые поля не могут быть обязательными, иначе при чтении старых данных возникнут ошибки.

Удаление полей возможно только для необязательных, и повторное использование номеров тегов недопустимо, чтобы избежать путаницы с ранее закодированными данными. Это поддерживает как прямую, так и обратную совместимость.

### Типы данных и эволюция схемы

Изменение типа данных поля в Thrift и Protocol Buffers возможно, но с риском потери точности. Например, при замене 32-битного целого числа на 64-битное новый код сможет читать старые данные, заполняя недостающие биты нулями. Однако старый код может усечь 64-битное значение, если оно не помещается в 32 бита.

Protocol Buffers не имеет отдельных типов для списков, используя маркер repeated, что позволяет менять поля optional на repeated. Старый код прочитает только последний элемент. В Thrift есть специализированный тип для списков, но изменение поля с одним значением на поле с несколькими невозможно.

### Avro

Apache Avro — двоичный формат, созданный в 2009 году как часть Hadoop, учитывая недостатки Thrift для этого сценария. Avro использует схемы для задания структуры данных, поддерживая два языка описания схем: Avro IDL для редактирования людьми и JSON для автоматического считывания.

Схема в Avro не имеет номеров тегов, что позволяет получить очень компактное кодирование. Например, запись в формате Avro занимает всего 32 байта. Закодированные данные представляют собой последовательность значений без явной идентификации полей или их типов, что требует, чтобы код, читающий данные, использовал ту же схему, что и код, записывающий их. 

Для обеспечения эволюции схемы Avro применяет разные подходы, позволяющие добавлять, удалять и изменять поля, что обеспечивает совместимость между версиями схем.

### Схема для чтения и схема для записи

В Apache Avro существует два типа схем: схема для записи (writer's schema) и схема для чтения (reader's schema). Схема для записи используется приложением при кодировании данных, а схема для чтения — при их декодировании. Эти схемы не обязаны совпадать, главное — чтобы они были совместимы.

При декодировании Avro разрешает конфликты между схемами, сопоставляя поля по именам. Если в схеме для записи есть поле, которого нет в схеме для чтения, оно игнорируется. Если ожидаемое поле отсутствует в записи, оно заполняется значением по умолчанию, указанным в схеме для чтения. Это обеспечивает гибкость и совместимость при изменениях схем.

### Правила эволюции схемы

