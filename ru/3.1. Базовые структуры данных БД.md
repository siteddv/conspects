```bash
#!/bin/bash
db_set () {
echo "$1,$2" >> database
}
db_get () {
grep "^$1," database | sed -e "s/^$1,//" | tail -n 1
}
```

В данной реализации самой простой базы данных используется две функции на Bash: `db_set` для сохранения пар «ключ — значение» и `db_get` для их поиска. Данные хранятся в текстовом файле, где каждая строка представляет собой пару, разделенную запятой. При добавлении новой пары данные добавляются в конец файла, что эффективно, но поиск значения по ключу в `db_get` становится медленным, поскольку функция просматривает весь файл, что приводит к сложности O(n).

Для повышения производительности поиска необходимо внедрить индекс — дополнительную структуру данных, которая служит указателем для ускорения доступа к основным данным. Индексы позволяют эффективно находить значения по ключам, но их использование также увеличивает накладные расходы, особенно при записи данных, так как каждый раз при добавлении или обновлении записи необходимо обновлять и индекс.

Индексы не только ускоряют чтение, но и могут замедлить операции записи. Поэтому базы данных обычно не индексируют все возможные поля, а позволяют разработчикам вручную выбирать, какие индексы создавать, основываясь на паттернах запросов. Это позволяет сбалансировать преимущества ускоренного доступа к данным и затраты на их обновление, обеспечивая максимальную эффективность приложения.

### Хеш-индексы

Индексы для данных типа «ключ — значение» являются основой для построения более сложных структур данных и часто реализуются с использованием хеш-карт. Хеш-карты, как известные структуры данных, эффективно сопоставляют ключи и значения, что делает их удобными для индексирования. При работе с хранилищами данных типа «ключ — значение», где данные добавляются в конец файла, простейшая стратегия индексации включает использование хеш-карты в оперативной памяти, где каждому ключу соответствует смещение в файле, указывающее на местоположение его значения.

![[12. Key-Value  HashMap.png]]

При добавлении новой пары «ключ — значение» хеш-карта обновляется, что позволяет быстро находить значения по ключам. Этот подход позволяет добиться высокой производительности чтения и записи, поскольку значения могут загружаться с диска по их относительному адресу, особенно если они уже находятся в кэше файловой системы. Такой метод был применён в Bitcask — подсистеме хранения для распределенной NoSQL СУБД Riak, подходящей для частых обновлений значений.

Однако просто добавлять данные в конец файла может привести к исчерпанию места на диске. Эффективным решением является сегментация журнала, где каждый сегмент имеет фиксированный размер. Когда сегмент достигает предела, он закрывается, а новые данные записываются в новый файл. Для оптимизации хранения применяется уплотнение (compaction), которое устраняет дублирующиеся ключи и оставляет только последние значения, тем самым уменьшая размер сегментов.

Сегменты также могут быть объединены в процессе уплотнения, что позволяет уменьшить количество файлов и упростить поиск значений. При каждом поиске значения сначала проверяется хеш-карта последнего сегмента, и, если ключ не найден, проверяются предыдущие сегменты. Это делает процесс поиска более быстрым, поскольку количество сегментов остаётся небольшим.

![[13. Merge process.png]]

Для реализации такой системы необходимо учитывать различные аспекты, такие как формат файлов (рекомендуется использовать двоичный формат для улучшения производительности), удаление записей (с использованием отметок об удалении), восстановление после сбоев (хранение состояния хеш-карт на диске) и управление конкурентным доступом.

Несмотря на преимущества, хеш-таблицы имеют свои ограничения. Они требуют, чтобы вся хеш-карта помещалась в оперативной памяти, что может быть проблематично при большом количестве ключей. Также запросы по диапазону неэффективны, так как их нельзя легко просматривать в отличие от других структур данных.

В целом, индексы на основе хеш-карт предоставляют эффективный механизм для работы с данными типа «ключ — значение», обеспечивая быстрый доступ к значениям и минимизируя затраты на операции записи и чтения.

### SS-таблицы и LSM-деревья

Теперь мы рассматриваем новый формат файлов сегментов, называемый отсортированной строковой таблицей (SS-таблицей). В отличие от журнальных сегментов, где пары «ключ — значение» записываются в порядке добавления, в SS-таблицах данные упорядочены по ключам, что обеспечивает ряд преимуществ.

Эффективное объединение сегментов: Объединение SS-таблиц происходит просто и эффективно, даже если размер файлов превышает объем оперативной памяти. Используется метод, аналогичный сортировке слиянием (mergesort), при котором читаются несколько входных файлов, и записывается самый маленький ключ в выходной файл. При наличии дублирующихся ключей выбирается значение из наиболее свежего сегмента.

Поиск ключей: Для нахождения конкретного ключа не требуется хранить индекс всех ключей в памяти. Используя отсортированное расположение, можно перейти к смещению ближайшего ключа и просмотреть записи в диапазоне до нахождения искомого ключа.

Разреженный индекс: Хотя всё ещё необходим индекс в оперативной памяти, он может быть разреженным — достаточно одного ключа на несколько килобайт сегмента. Это снижает объем памяти, необходимый для хранения индекса.

![[14. SS-table index.png]]

Кроме того, записи можно сгруппировать в блоки и сжать перед записью на диск. Каждая запись разреженного индекса будет указывать на начало сжатого блока, что экономит место и снижает нагрузку на ввод/вывод.

Таким образом, SS-таблицы предлагают эффективный и упорядоченный способ хранения данных, улучшая производительность как при записи, так и при чтении.

### Создание и поддержание SS-таблиц

Для сортировки данных по ключу при записи в базе данных используется MemTable — сбалансированная структура данных, расположенная в оперативной памяти (например, красно-черное дерево). При поступлении новых записей они добавляются в MemTable. Как только её размер превышает заданный порог (обычно несколько мегабайт), MemTable записывается на диск в формате SS-таблицы, которая содержит пары «ключ — значение» в отсортированном виде. Эта операция выполняется эффективно, так как данные уже организованы.

При обработке запросов на чтение сначала проверяется MemTable, затем последние сегменты на диске. Для упрощения поиска можно использовать двоичный поиск, но в случае переменного размера записей требуется индекс. Также запускается фоновой процесс слияния и уплотнения, чтобы объединять сегменты и удалять устаревшие значения. Чтобы избежать потери данных в случае сбоя, используется журнал, в который немедленно записываются операции. Этот журнал помогает восстановить MemTable после сбоя и может быть удалён после записи данных в SS-таблицу.

### Создание LSM-дерева из SS-таблиц

Описанный алгоритм используется в LevelDB и RocksDB — библиотек, ориентированных на хранение пар «ключ — значение». LevelDB также применяется в распределенной СУБД Riak как альтернатива Bitcask. Подобные системы реализованы в Cassandra и HBase, вдохновленных концепцией Bigtable от Google. Индексная структура, известная как журналированное дерево слияния (LSM-Tree), описана Патриком О’Нилом и основана на принципах журналированных файловых систем. Lucene, модуль индексации для Elasticsearch и Solr, использует схожий подход для полнотекстового поиска, храня термы и их соответствия в отсортированных файлах, позволяя выполнять слияние в фоновом режиме.

### Оптимизация производительности

Для обеспечения высокой производительности LSM-деревьев необходимо учитывать множество нюансов. Одной из проблем является медленная обработка запросов на отсутствие ключей, что требует последовательного просмотра MemTable и всех сегментов до самого старого, потенциально увеличивая количество операций чтения с диска. Эту проблему можно решить с помощью фильтров Блума, которые позволяют быстро определить, существует ли ключ, тем самым сокращая ненужные чтения.

Существуют различные стратегии уплотнения и слияния SS-таблиц, среди которых наиболее распространены уплотнение по слоям и поуровневое уплотнение. LevelDB и RocksDB используют поуровневое уплотнение, которое разбивает диапазоны ключей на меньшие таблицы и распределяет более старые данные по уровням, что снижает объем занимаемого дискового пространства. В HBase применяется уплотнение по слоям, а Cassandra поддерживает оба метода.

Несмотря на сложности, основная концепция LSM-деревьев — использование каскада SS-таблиц, которые объединяются в фоновом режиме, — остается простой и эффективной. Это позволяет успешно работать с наборами данных, значительно превышающими объем доступной оперативной памяти, а сортировка данных обеспечивает эффективные запросы по диапазонам и высокую пропускную способность для операций записи.

### B-деревья

ChatGPT

B-деревья, разработанные в 1970-х годах, остаются наиболее распространенной индексной структурой в реляционных и многих нереляционных базах данных. Эти деревья хранят пары «ключ — значение» в отсортированном виде, что обеспечивает эффективный поиск по ключу и запросы по диапазонам. В отличие от журналированных индексов, которые делят базу данных на сегменты переменного размера, B-деревья используют фиксированные страницы, обычно размером 4 Кбайт.

Структура B-дерева позволяет каждой странице ссылаться на дочерние страницы, создавая иерархию, где одна из страниц является корнем. При поиске ключа, например, 251, начинается с корня и переходит по ссылкам на дочерние страницы, постепенно сужая диапазон, пока не достигнет страницы-листа, содержащей нужное значение.

![[15. Searching B-tree.png]]

Коэффициент ветвления (branching factor) определяет, сколько ссылок на дочерние страницы может быть на одной странице. Он зависит от объема дискового пространства, выделенного для хранения ссылок и границ диапазонов, но обычно составляет несколько сотен.

Для обновления значения существующего ключа необходимо найти соответствующую страницу-лист, внести изменения и записать страницу обратно на диск. Если добавляется новый ключ, он помещается на страницу, соответствующую его диапазону. При нехватке места страница разбивается, а родительская страница обновляется, что помогает сохранять сбалансированность дерева.

![[16. Update B-tree index kry.png]]

Алгоритм обеспечивает, что глубина B-дерева с n ключами остается O(log n), что позволяет поддерживать низкую сложность поиска. Обычно деревья имеют глубину три или четыре уровня, что делает поиск достаточно быстрым даже для больших объемов данных. Например, четырехуровневое B-дерево с 4 Кбайт страницами и коэффициентом ветвления 500 может хранить до 256 Тбайт информации.

Таким образом, B-деревья представляют собой эффективное и надежное решение для индексации и быстрого доступа к данным в различных системах управления базами данных.

### Обеспечение надежности B-деревьев