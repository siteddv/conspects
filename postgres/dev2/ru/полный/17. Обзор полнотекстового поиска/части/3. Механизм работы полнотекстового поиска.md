### Часть 3: Механизм работы полнотекстового поиска

#### Этапы обработки текстового документа
Полнотекстовый поиск — это многоступенчатый процесс, который начинается с анализа исходного текстового документа и заканчивается формированием специального типа данных, называемого **tsvector** (вектор текста). Давайте разберем этот процесс более детально.

1. **Анализаторы (Parsers)**:
   - Первым шагом в работе полнотекстового поиска является пропускание документа через **анализатор** (parser). Анализатор разбивает текст на фрагменты различных типов.
   - По умолчанию используется анализатор под названием **default**, который умеет выделять около двух десятков типов фрагментов, таких как:
     - Слова
     - Числа
     - URL-адреса
     - Электронные адреса (email)
     - Разделители (например, знаки препинания)
   - Например, строка `"magic-time"` может быть разбита на два фрагмента: слово `magic` и слово `time`, а также черточку `-` как отдельный фрагмент.
   - Каждому фрагменту анализатор присваивает определенный тип, например, `word` (слово), `numword` (число), `url`, `email` и т.д.

2. **Словари (Dictionaries)**:
   - После того, как текст разбит на фрагменты, каждый фрагмент передается через цепочку **словарей**. Словарь — это программа, которая преобразует фрагменты в **лексемы** (lexemes).
   - Основная задача словарей — нормализация фрагментов. Это означает, что словари могут выполнять следующие операции:
     - **Приведение к нижнему регистру**: Все слова приводятся к нижнему регистру, чтобы избежать зависимости от регистра при поиске.
     - **Удаление стоп-слов**: Стоп-слова — это часто встречающиеся слова, которые не несут значимой информации для поиска (например, артикли в английском языке, предлоги в русском и т.д.). Эти слова удаляются из индекса.
     - **Стемминг (stemming)**: Стеммер пытается привести слово к его базовой форме (корню). Например, слова "magic", "magical", "magically" могут быть приведены к одной лексеме "magic".
     - **Обработка синонимов**: Некоторые словари могут объединять синонимы в одну лексему.
   
   - В PostgreSQL есть несколько стандартных словарей:
     - **Simple Dictionary**: Простой словарь, который просто приводит все слова к нижнему регистру и удаляет стоп-слова.
     - **Stemmer Dictionary**: Стеммер, который пытается привести слова к их корневой форме. Этот словарь зависит от языка (например, английский стеммер работает иначе, чем русский).
     - **Synonym Dictionary**: Словарь синонимов, который позволяет заменять одни слова другими (например, "USA" -> "United States").
     - **Ispell Dictionary**: Более сложный словарь, который использует алгоритмы для проверки правописания и морфологического анализа.

3. **Цепочки словарей**:
   - Для каждого типа фрагмента можно настроить свою цепочку словарей. Например, для слов можно использовать стеммер, а для email-адресов или URL-адресов словари вообще не нужны.
   - Цепочка словарей работает следующим образом:
     - Первый словарь в цепочке пытается распознать фрагмент. Если он успешно распознал фрагмент, то результат передается дальше, и последующие словари уже не вызываются.
     - Если первый словарь не смог распознать фрагмент, то он передается следующему словарю в цепочке.
     - Например, если мы имеем дело со словом на английском языке, то сначала может быть вызван словарь стеммера, который приведет слово к его базовой форме. Если же слово не было распознано стеммером, то оно может быть передано в словарь синонимов или другой словарь.

4. **Конфигурации полнотекстового поиска**:
   - Конфигурация полнотекстового поиска определяет, какой анализатор и какие словари будут использоваться для каждого типа фрагмента.
   - PostgreSQL предоставляет предопределенные конфигурации для разных языков (например, `english`, `russian`, `french` и т.д.). Эти конфигурации содержат настройки для работы с конкретным языком, включая использование соответствующих словарей и анализаторов.
   - Вы можете создавать свои собственные конфигурации, изменяя цепочки словарей или добавляя новые словари. Например, можно настроить конфигурацию так, чтобы для английских слов использовался словарь, который удаляет критические знаки (например, точки или запятые).

5. **Преобразование в tsvector**:
   - После того, как все фрагменты были обработаны через анализатор и словари, они собираются в специальный тип данных — **tsvector**.
   - **tsvector** — это набор лексем с указанием их позиций в исходном документе. Например, если у нас есть текст `"The magic time is now"`, то после обработки он может быть преобразован в такой tsvector:
     ```
     'magic':2 'time':3 'now':5
     ```
     Здесь каждая лексема сопровождается номером позиции, где она встречается в исходном тексте.
   - Позиции важны для выполнения **фразового поиска** (phrase search) и ранжирования результатов.

6. **Поисковый запрос (tsquery)**:
   - Поисковый запрос также преобразуется в специальный тип данных — **tsquery**.
   - **tsquery** представляет собой набор лексем, соединенных логическими операторами (`AND`, `OR`, `NOT`) и дополнительными конструкциями, такими как фразовый поиск или поиск с учетом расстояния между словами.
   - Например, запрос `"magic & time"` будет преобразован в tsquery, который ищет документы, содержащие оба слова "magic" и "time".
   - Можно использовать более сложные конструкции, такие как двойная стрелка (`<->`), которая указывает, что слова должны находиться рядом друг с другом. Например, запрос `"magic <-> time"` найдет только те документы, где слова "magic" и "time" идут строго друг за другом.

#### Типы фрагментов и их обработка
Как уже упоминалось, анализатор разбивает текст на различные типы фрагментов. Вот основные типы фрагментов и их обработка:

- **Words (слова)**:
  - Обрабатываются через цепочку словарей, которые могут включать стеммеры, синонимы и другие инструменты нормализации.
  - Пример: слово "Magic" может быть приведено к нижнему регистру и стемму "magic".

- **Numbers (числа)**:
  - Числа обычно не обрабатываются через словари, но могут быть сохранены как отдельные лексемы.
  - Пример: число "123" будет сохранено как лексема без изменений.

- **URLs и Emails**:
  - Эти фрагменты обычно не обрабатываются через словари, так как они уже имеют уникальную структуру.
  - Пример: URL `https://example.com` или email `user@example.com` будут сохранены как есть.

- **Разделители (punctuation)**:
  - Знаки препинания обычно игнорируются или используются для разделения слов.
  - Пример: запятая `,` или точка `.` не будут сохранены как лексемы.

#### Работа со стоп-словами и словоформами
- **Стоп-слова**:
  - Стоп-слова — это часто встречающиеся слова, которые не несут значимой информации для поиска. Например, в английском языке это артикли ("the", "a"), предлоги ("in", "on") и т.д.
  - Эти слова удаляются из индекса, чтобы уменьшить размер индекса и повысить эффективность поиска.

- **Словоформы**:
  - Система должна уметь работать с различными формами одного и того же слова. Например, слова "magic", "magical", "magically" должны быть приведены к одной лексеме "magic".
  - Это достигается с помощью **стеммеров** или **морфологических анализаторов**, которые приводят слова к их базовой форме.

#### Итоги
Полнотекстовый поиск — это сложный процесс, который включает в себя несколько этапов:
1. Разбиение текста на фрагменты с помощью анализатора.
2. Нормализация фрагментов через цепочку словарей.
3. Формирование специального типа данных (**tsvector**) для хранения лексем и их позиций.
4. Преобразование поискового запроса в **tsquery**.
5. Выполнение поиска и ранжирование результатов.

Эта часть конспекта подробно описывает механизм работы полнотекстового поиска. В следующей части мы рассмотрим настройку и конфигурацию полнотекстового поиска, включая создание индексов и использование различных словарей для оптимизации поиска.

